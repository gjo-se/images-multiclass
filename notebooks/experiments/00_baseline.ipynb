{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a03e81b8b6c096a4",
   "metadata": {},
   "source": [
    "# Einleitung\n",
    "- <a href=\"https://colab.research.google.com/github/gjo-se/images-multiclass/blob/master/notebooks/experiments/00_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "- Ziel des Notebooks und des Experiments Kontext und Motivation\n",
    "- ganz zum Schluss per ChatGPT erstellen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730092dcd45ceac8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbbc689b60b96a4d",
   "metadata": {},
   "source": [
    "# Imports & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4097a4da37bbb182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T15:54:03.408640Z",
     "start_time": "2026-01-29T15:54:03.390329Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60e3f8207ec4dc",
   "metadata": {},
   "source": [
    "## Clone git on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467ce42bc3321731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T15:51:41.487979Z",
     "start_time": "2026-01-29T15:51:41.439336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clone_and_cd_repo() wird nur auf Google Colab ausgeführt.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "\n",
    "    repo_url = \"https://github.com/gjo-se/images-multiclass.git\"\n",
    "    target_dir = \"/content\"\n",
    "    notebook_dir = \"notebooks/experiments/\"\n",
    "\n",
    "    if not os.path.exists(os.path.join(target_dir, \"src\")):\n",
    "        print(f\"Cloning repository {repo_url} to {target_dir}/tmp_clone ...\")\n",
    "        subprocess.check_call([\"git\", \"clone\", repo_url, f\"{target_dir}/tmp_clone\"])\n",
    "        for item in os.listdir(f\"{target_dir}/tmp_clone\"):\n",
    "            subprocess.check_call([\"mv\", f\"{target_dir}/tmp_clone/{item}\", target_dir])\n",
    "        subprocess.check_call([\"rm\", \"-rf\", f\"{target_dir}/tmp_clone\"])\n",
    "    else:\n",
    "        print(f\"Projekt bereits in {target_dir} vorhanden.\")\n",
    "\n",
    "    os.chdir(os.path.join(target_dir, notebook_dir))\n",
    "    print(f\"Changed working directory to {os.getcwd()}\")\n",
    "else:\n",
    "    print(\"clone_and_cd_repo() wird nur auf Google Colab ausgeführt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f40b5816311bf80",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e38223abb8cb5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T12:03:03.716157Z",
     "start_time": "2026-01-29T12:03:03.179568Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook last run (end-to-end): 2026-01-29 13:03:03.702252\n",
      "TensorFlow Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "from src.setup import SetupEnvironment\n",
    "\n",
    "SetupEnvironment();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff89a0f821896521",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "Laden und Vorverarbeiten der Daten\n",
    "Explorative Datenanalyse (EDA) mit Visualisierungen\n",
    "Aufteilen in Trainings-, Validierungs- und Testdaten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66f1064600696c7",
   "metadata": {},
   "source": [
    "# Explorative Datenanalyse (EDA) für Food-101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c27c9866376e17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T07:23:54.880434Z",
     "start_time": "2026-01-30T07:23:12.377548Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Variant folder /Users/gregoryjodaily/tensorflow_datasets/food101/2.0.0 has no dataset_info.json\n",
      "/Users/gregoryjodaily/Dropbox/5-Berufsleben/gjoSe/Development/Projects/python/image-multiclass-tf/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /Users/gregoryjodaily/tensorflow_datasets/food101/2.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 274.33 url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 209.68 url/s]\n",
      "Dl Size...:   0%|          | 0/4996278331 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 178.66 url/s]\n",
      "Dl Size...: 100%|██████████| 4996278331/4996278331 [00:00<00:00, 921462940323.04 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 4996278331/4996278331 [00:00<00:00, 678931840498.50 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 121.46 url/s]\n",
      "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train examples...: 5299 examples [00:01, 5298.12 examples/s]\u001b[A\n",
      "Generating train examples...: 10598 examples [00:02, 5223.70 examples/s]\u001b[A\n",
      "Generating train examples...: 15846 examples [00:03, 5234.53 examples/s]\u001b[A\n",
      "Generating train examples...: 21082 examples [00:04, 4336.13 examples/s]\u001b[A\n",
      "Generating train examples...: 25604 examples [00:05, 3939.34 examples/s]\u001b[A\n",
      "Generating train examples...: 29690 examples [00:07, 3728.03 examples/s]\u001b[A\n",
      "Generating train examples...: 33512 examples [00:09, 2914.46 examples/s]\u001b[A\n",
      "Generating train examples...: 36699 examples [00:10, 2547.16 examples/s]\u001b[A\n",
      "Generating train examples...: 39462 examples [00:12, 2346.25 examples/s]\u001b[A\n",
      "Generating train examples...: 42294 examples [00:13, 2455.10 examples/s]\u001b[A\n",
      "Generating train examples...: 45679 examples [00:14, 2680.65 examples/s]\u001b[A\n",
      "Generating train examples...: 49107 examples [00:15, 2872.94 examples/s]\u001b[A\n",
      "Generating train examples...: 52709 examples [00:16, 3068.90 examples/s]\u001b[A\n",
      "Generating train examples...: 56091 examples [00:17, 3155.62 examples/s]\u001b[A\n",
      "Generating train examples...: 59725 examples [00:18, 3291.30 examples/s]\u001b[A\n",
      "Generating train examples...: 63091 examples [00:20, 2481.03 examples/s]\u001b[A\n",
      "Generating train examples...: 65913 examples [00:22, 2277.43 examples/s]\u001b[A\n",
      "Generating train examples...: 68989 examples [00:23, 2461.50 examples/s]\u001b[A\n",
      "Generating train examples...: 71911 examples [00:24, 2575.43 examples/s]\u001b[A\n",
      "Generating train examples...: 74673 examples [00:25, 2183.47 examples/s]\u001b[A\n",
      "                                                                        \u001b[A\n",
      "Shuffling /Users/gregoryjodaily/tensorflow_datasets/food101/incomplete.HB2NOZ_2.0.0/food101-train.tfrecord*...:   0%|          | 0/75750 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling /Users/gregoryjodaily/tensorflow_datasets/food101/incomplete.HB2NOZ_2.0.0/food101-train.tfrecord*...:  24%|██▍       | 18469/75750 [00:01<00:03, 18430.77 examples/s]\u001b[A\n",
      "Shuffling /Users/gregoryjodaily/tensorflow_datasets/food101/incomplete.HB2NOZ_2.0.0/food101-train.tfrecord*...:  50%|████▉     | 37586/75750 [00:02<00:02, 18834.07 examples/s]\u001b[A\n",
      "Shuffling /Users/gregoryjodaily/tensorflow_datasets/food101/incomplete.HB2NOZ_2.0.0/food101-train.tfrecord*...:  74%|███████▍  | 56421/75750 [00:04<00:01, 12878.94 examples/s]\u001b[A\n",
      "Shuffling /Users/gregoryjodaily/tensorflow_datasets/food101/incomplete.HB2NOZ_2.0.0/food101-train.tfrecord*...:  94%|█████████▎| 70928/75750 [00:05<00:00, 11198.93 examples/s]\u001b[A\n",
      "Generating splits...:  50%|█████     | 1/2 [00:32<00:32, 32.76s/ splits]                                                                                                       \u001b[A\n",
      "Generating validation examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating validation examples...: 3426 examples [00:01, 3425.67 examples/s]\u001b[A\n",
      "Generating validation examples...: 7833 examples [00:02, 4002.54 examples/s]\u001b[A\n",
      "Generating validation examples...: 12625 examples [00:03, 4362.73 examples/s]\u001b[A\n",
      "Generating validation examples...: 17706 examples [00:04, 4645.99 examples/s]\u001b[A\n",
      "Generating validation examples...: 22352 examples [00:05, 3672.94 examples/s]\u001b[A\n",
      "                                                                             \u001b[A\n",
      "Shuffling /Users/gregoryjodaily/tensorflow_datasets/food101/incomplete.HB2NOZ_2.0.0/food101-validation.tfrecord*...:   0%|          | 0/25250 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                                                                                                                                     \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset food101 downloaded and prepared to /Users/gregoryjodaily/tensorflow_datasets/food101/2.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from src.data import Dataset\n",
    "\n",
    "DATASET_NAME = \"food101\" # https://www.tensorflow.org/datasets/catalog/food101\n",
    "Dataset().load_dataset(DATASET_NAME);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b57bab92fc0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Lade die ds_info für Metadaten\n",
    "_, _, ds_info = get_datasets(batch_size=1)\n",
    "\n",
    "# Klassen anzeigen\n",
    "class_names = ds_info.features['label'].names\n",
    "print(f\"Anzahl Klassen: {len(class_names)}\")\n",
    "print(f\"Beispielklassen: {class_names[:10]}\")\n",
    "\n",
    "# Beispielbilder visualisieren\n",
    "train_ds, _, _ = get_datasets(batch_size=9)\n",
    "for images, labels in train_ds.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy())\n",
    "        plt.title(class_names[labels[i].numpy()])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Klassenverteilung analysieren\n",
    "train_raw = tfds.load(\"food101\", split=\"train\", as_supervised=True)\n",
    "labels = []\n",
    "for _, label in train_raw:\n",
    "    labels.append(label.numpy())\n",
    "labels = np.array(labels)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.hist(labels, bins=len(class_names))\n",
    "plt.title(\"Klassenverteilung im Trainingsdatensatz\")\n",
    "plt.xlabel(\"Klasse\")\n",
    "plt.ylabel(\"Anzahl Bilder\")\n",
    "plt.show()\n",
    "\n",
    "# Bildgrößen prüfen\n",
    "shapes = []\n",
    "for image, _ in train_raw.take(100):\n",
    "    shapes.append(image.shape)\n",
    "shapes = np.array(shapes)\n",
    "print(f\"Beispiel-Bildgrößen (erste 10): {shapes[:10]}\")\n",
    "print(f\"Minimale Bildgröße: {shapes.min(axis=0)}\")\n",
    "print(f\"Maximale Bildgröße: {shapes.max(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708536bedeecff47",
   "metadata": {},
   "source": [
    "# Modellierung\n",
    "Definition und Visualisierung des Modells\n",
    "Kompilieren des Modells (Loss, Optimizer, Metriken)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b307daecca1037",
   "metadata": {},
   "source": [
    "# Training\n",
    "Training des Modells mit Trainingsdaten\n",
    "Visualisierung des Trainingsverlaufs (Loss, Accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42505bf8a8858af4",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Bewertung des Modells auf Validierungs- und Testdaten\n",
    "Darstellung von Metriken und ggf. Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59121c59cc0cd0",
   "metadata": {},
   "source": [
    "# Ergebnisse und Interpretation\n",
    "Zusammenfassung der wichtigsten Erkenntnisse\n",
    "Diskussion von Stärken, Schwächen und möglichen Verbesserungen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3125bb29a1ff72e",
   "metadata": {},
   "source": [
    "# Speicherung und Laden von Modellen\n",
    "Speichern des trainierten Modells\n",
    "Laden und Testen des gespeicherten Modells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5ec4799a0f77be",
   "metadata": {},
   "source": [
    "# Fazit und Ausblick\n",
    "Kurzes Fazit und mögliche nächste Schritte\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa48e15810ae75",
   "metadata": {},
   "source": [
    "# Anhang\n",
    "Zusätzliche Visualisierungen, Code-Snippets oder Referenzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f2dc0d74a2310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
